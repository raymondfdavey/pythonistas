{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'dog', 'b': 'cat'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = dict([(\"a\", \"dog\"), (\"b\", \"cat\")])\n",
    "hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Python's zip Function: An Interactive Guide\n",
    "\n",
    "## 1. Basic Concepts\n",
    "\n",
    "The `zip()` function creates an iterator of tuples where each tuple contains the i-th element from each of the input iterables. It's like a zipper, bringing together corresponding elements!\n",
    "\n",
    "### 1.1 Basic Usage\n",
    "```python\n",
    "numbers = [1, 2, 3]\n",
    "letters = ['a', 'b', 'c']\n",
    "zipped = zip(numbers, letters)\n",
    "print(list(zipped))  # Output: [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "```\n",
    "\n",
    "### 1.2 Important Properties\n",
    "\n",
    "1. **Creates an Iterator:**\n",
    "```python\n",
    "zipped = zip(numbers, letters)\n",
    "print(zipped)  # Output: <zip object at 0x...>\n",
    "# Must convert to list/tuple/etc to see contents\n",
    "```\n",
    "\n",
    "2. **Single-Use Iterator:**\n",
    "```python\n",
    "zipped = zip(numbers, letters)\n",
    "print(list(zipped))  # Shows contents\n",
    "print(list(zipped))  # Empty! Iterator is exhausted\n",
    "```\n",
    "\n",
    "3. **Stops at Shortest Input:**\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "letters = ['a', 'b']\n",
    "print(list(zip(numbers, letters)))  # Output: [(1, 'a'), (2, 'b')]\n",
    "```\n",
    "\n",
    "## 2. Common Use Cases\n",
    "\n",
    "### 2.1 Creating Dictionaries\n",
    "```python\n",
    "keys = ['name', 'age', 'city']\n",
    "values = ['Alice', 25, 'New York']\n",
    "user_dict = dict(zip(keys, values))\n",
    "print(user_dict)  # Output: {'name': 'Alice', 'age': 25, 'city': 'New York'}\n",
    "```\n",
    "\n",
    "### 2.2 Parallel Iteration\n",
    "```python\n",
    "names = ['Alice', 'Bob', 'Charlie']\n",
    "scores = [85, 92, 78]\n",
    "\n",
    "for name, score in zip(names, scores):\n",
    "    print(f\"{name} scored {score}\")\n",
    "```\n",
    "\n",
    "### 2.3 Matrix Transposition\n",
    "```python\n",
    "matrix = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "transposed = list(zip(*matrix))\n",
    "print(transposed)  # Output: [(1, 4, 7), (2, 5, 8), (3, 6, 9)]\n",
    "```\n",
    "\n",
    "### 2.4 Unzipping with zip(*...)\n",
    "```python\n",
    "pairs = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "numbers, letters = zip(*pairs)\n",
    "print(numbers)  # Output: (1, 2, 3)\n",
    "print(letters)  # Output: ('a', 'b', 'c')\n",
    "```\n",
    "\n",
    "## 6. Best Practices and Tips\n",
    "\n",
    "1. **Memory Efficiency:**\n",
    "   - zip creates an iterator, not a list\n",
    "   - Convert to list/tuple only when needed\n",
    "   - Use itertools.zip_longest() if you need to handle uneven lengths\n",
    "\n",
    "2. **Common Patterns:**\n",
    "   ```python\n",
    "   # Dictionary construction\n",
    "   dict(zip(keys, values))\n",
    "   \n",
    "   # Parallel iteration\n",
    "   for x, y, z in zip(xs, ys, zs)\n",
    "   \n",
    "   # Unzipping\n",
    "   xs, ys = zip(*pairs)\n",
    "   ```\n",
    "\n",
    "3. **Gotchas to Watch Out For:**\n",
    "   - Iterator exhaustion\n",
    "   - Uneven lengths (stops at shortest)\n",
    "   - Forgetting to convert to list/tuple when needed\n",
    "\n",
    "## Further Exercises\n",
    "\n",
    "1. Create a function that merges multiple sorted lists while maintaining order\n",
    "2. Implement a round-robin tournament scheduler using zip\n",
    "3. Create a function that interleaves multiple strings\n",
    "4. Build a simple spreadsheet column calculator using zip\n",
    "5. Create a function that validates that corresponding elements in multiple lists meet certain criteria\n",
    "\n",
    "Happy coding! ðŸâœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practice Problems\n",
    "\n",
    "### Problem 1: Team Pairing\n",
    "Create a function that pairs up team members for a project. If there's an odd number of people, the last person should be paired with \"Waiting for partner\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(team_members):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test cases\n",
    "team1 = ['Alice', 'Bob', 'Charlie', 'David']\n",
    "team2 = ['Alice', 'Bob', 'Charlie']\n",
    "print(create_pairs(team1))  # Should output: [('Alice', 'Bob'), ('Charlie', 'David')]\n",
    "print(create_pairs(team2))  # Should output: [('Alice', 'Bob'), ('Charlie', 'Waiting for partner')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Grade Analyzer\n",
    "Write a function that takes lists of students, their grades, and attendance rates, and returns a list of students who meet both criteria: grade > 80 and attendance > 90%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'David']\n"
     ]
    }
   ],
   "source": [
    "def find_top_students(students, grades, attendance):\n",
    "    students_and_grades = zip(students, grades, attendance)\n",
    "    top_students = []\n",
    "    for student, grade, attendance in students_and_grades:\n",
    "        if grade > 80 and attendance > 90:\n",
    "            top_students.append(student)\n",
    "    return top_students\n",
    "\n",
    "# Test case\n",
    "students = ['Alice', 'Bob', 'Charlie', 'David']\n",
    "grades = [85, 92, 78, 95]\n",
    "attendance = [92, 88, 95, 96]\n",
    "print(find_top_students(students, grades, attendance))\n",
    "# Should output: ['Alice', 'David']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: CSV Column Swapper\n",
    "Create a function that takes lists representing CSV columns and returns new columns with specified columns swapped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A1', 'B1', 'C1')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def swap_columns(columns, pos1, pos2):\n",
    "    col1, col2, col3 = zip(*columns)\n",
    "    indices = [0, 1, 2]\n",
    "\n",
    "    print(col1)\n",
    "    pass\n",
    "\n",
    "# Test case\n",
    "data = [\n",
    "    ['A1', 'A2', 'A3'],\n",
    "    ['B1', 'B2', 'B3'],\n",
    "    ['C1', 'C2', 'C3']\n",
    "]\n",
    "print(swap_columns(data, 0, 2))\n",
    "# Should output: [['A3', 'A2', 'A1'], ['B3', 'B2', 'B1'], ['C3', 'C2', 'C1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Moving Average Calculator\n",
    "Create a function that calculates the moving average of paired time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_average(times, values, window_size=3):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test case\n",
    "times = [1, 2, 3, 4, 5, 6]\n",
    "values = [10, 20, 30, 40, 50, 60]\n",
    "print(calculate_moving_average(times, values))\n",
    "# Should output: [(2, 20.0), (3, 30.0), (4, 40.0), (5, 50.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Challenges\n",
    "\n",
    "### Challenge 1: Custom Zipper\n",
    "Implement your own version of zip that allows specifying a fill value for shorter iterables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_zip(*iterables, fill=None):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test case\n",
    "nums = [1, 2]\n",
    "letters = ['a', 'b', 'c']\n",
    "print(list(custom_zip(nums, letters, fill=0)))\n",
    "# Should output: [(1, 'a'), (2, 'b'), (0, 'c')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Data Transformer\n",
    "Create a function that transforms rows of data into columns while applying different transformations to each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(rows, transformations):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test case\n",
    "data = [\n",
    "    ['1', '2.5', 'hello'],\n",
    "    ['2', '3.7', 'world'],\n",
    "    ['3', '4.1', 'python']\n",
    "]\n",
    "transforms = [int, float, str.upper]\n",
    "print(transform_data(data, transforms))\n",
    "# Should output: [[1, 2, 3], [2.5, 3.7, 4.1], ['HELLO', 'WORLD', 'PYTHON']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solutions\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solutions</summary>\n",
    "\n",
    "### Solution 1: Team Pairing\n",
    "```python\n",
    "def create_pairs(team_members):\n",
    "    # Add 'Waiting for partner' if odd number of members\n",
    "    if len(team_members) % 2:\n",
    "        team_members = list(team_members) + ['Waiting for partner']\n",
    "    # Use zip to create pairs, stepping by 2\n",
    "    return list(zip(team_members[::2], team_members[1::2]))\n",
    "```\n",
    "\n",
    "### Solution 2: Grade Analyzer\n",
    "```python\n",
    "def find_top_students(students, grades, attendance):\n",
    "    return [student for student, grade, attend in zip(students, grades, attendance)\n",
    "            if grade > 80 and attend > 90]\n",
    "```\n",
    "\n",
    "### Solution 3: CSV Column Swapper\n",
    "```python\n",
    "def swap_columns(columns, pos1, pos2):\n",
    "    # Transpose the data\n",
    "    transposed = list(zip(*columns))\n",
    "    # Convert to list to allow modification\n",
    "    transposed = list(map(list, transposed))\n",
    "    # Swap columns\n",
    "    transposed[pos1], transposed[pos2] = transposed[pos2], transposed[pos1]\n",
    "    # Transpose back\n",
    "    return list(map(list, zip(*transposed)))\n",
    "```\n",
    "\n",
    "### Solution 4: Moving Average Calculator\n",
    "```python\n",
    "def calculate_moving_average(times, values, window_size=3):\n",
    "    pairs = list(zip(times, values))\n",
    "    result = []\n",
    "    for i in range(len(pairs) - window_size + 1):\n",
    "        window = pairs[i:i + window_size]\n",
    "        avg_time = window[window_size // 2][0]\n",
    "        avg_value = sum(v for _, v in window) / window_size\n",
    "        result.append((avg_time, avg_value))\n",
    "    return result\n",
    "```\n",
    "\n",
    "### Solution: Custom Zipper\n",
    "```python\n",
    "def custom_zip(*iterables, fill=None):\n",
    "    iterators = [iter(it) for it in iterables]\n",
    "    while True:\n",
    "        values = []\n",
    "        for iterator in iterators:\n",
    "            try:\n",
    "                value = next(iterator)\n",
    "            except StopIteration:\n",
    "                value = fill\n",
    "            values.append(value)\n",
    "        if all(v is fill for v in values):\n",
    "            break\n",
    "        yield tuple(values)\n",
    "```\n",
    "\n",
    "### Solution: Data Transformer\n",
    "```python\n",
    "def transform_data(rows, transformations):\n",
    "    # Transpose the data\n",
    "    columns = list(zip(*rows))\n",
    "    # Apply transformations\n",
    "    return [\n",
    "        [transform(value) for value in column]\n",
    "        for transform, column in zip(transformations, columns)\n",
    "    ]\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced zip Patterns in Python and ML Pipelines\n",
    "\n",
    "## 1. Data Pipeline Patterns\n",
    "\n",
    "### 1.1 Batched Dataset Iterator\n",
    "Common in deep learning for creating mini-batches:\n",
    "\n",
    "```python\n",
    "class BatchIterator:\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_samples = len(X)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = list(range(self.n_samples))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        for i in range(0, self.n_samples, self.batch_size):\n",
    "            batch_indices = indices[i:i + self.batch_size]\n",
    "            yield (\n",
    "                np.array([self.X[j] for j in batch_indices]),\n",
    "                np.array([self.y[j] for j in batch_indices])\n",
    "            )\n",
    "\n",
    "# Usage\n",
    "X = np.array([[1,2], [3,4], [5,6], [7,8]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "batches = BatchIterator(X, y, batch_size=2)\n",
    "for X_batch, y_batch in batches:\n",
    "    print(f\"X batch: {X_batch}, y batch: {y_batch}\")\n",
    "```\n",
    "\n",
    "### 1.2 Multi-Stream Data Processing\n",
    "Handling multiple synchronized data streams (e.g., images, text, and labels):\n",
    "\n",
    "```python\n",
    "class MultiModalDataset:\n",
    "    def __init__(self, image_paths, text_data, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.text_data = text_data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def process_image(self, path):\n",
    "        # Simulated image processing\n",
    "        return f\"processed_{path}\"\n",
    "        \n",
    "    def tokenize_text(self, text):\n",
    "        # Simulated text tokenization\n",
    "        return f\"tokenized_{text}\"\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for img_path, text, label in zip(self.image_paths, self.text_data, self.labels):\n",
    "            yield (\n",
    "                self.process_image(img_path),\n",
    "                self.tokenize_text(text),\n",
    "                label\n",
    "            )\n",
    "\n",
    "# Usage\n",
    "dataset = MultiModalDataset(\n",
    "    image_paths=['img1.jpg', 'img2.jpg'],\n",
    "    text_data=['text1', 'text2'],\n",
    "    labels=[0, 1]\n",
    ")\n",
    "for processed_img, tokenized_text, label in dataset:\n",
    "    print(f\"{processed_img}, {tokenized_text}, {label}\")\n",
    "```\n",
    "\n",
    "### 1.3 Time Series Window Generator\n",
    "Creating sliding windows over multiple time series:\n",
    "\n",
    "```python\n",
    "def create_windows(sequences, window_size, stride=1):\n",
    "    \"\"\"Create sliding windows over multiple synchronized sequences.\"\"\"\n",
    "    n_samples = len(sequences[0])\n",
    "    indices = range(0, n_samples - window_size + 1, stride)\n",
    "    \n",
    "    return zip(*[\n",
    "        zip(*[seq[i:i + window_size] for i in indices])\n",
    "        for seq in sequences\n",
    "    ])\n",
    "\n",
    "# Usage\n",
    "price = [1, 2, 3, 4, 5]\n",
    "volume = [10, 20, 30, 40, 50]\n",
    "sentiment = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for price_window, volume_window, sentiment_window in create_windows(\n",
    "    [price, volume, sentiment], \n",
    "    window_size=3\n",
    "):\n",
    "    print(f\"Price: {price_window}\")\n",
    "    print(f\"Volume: {volume_window}\")\n",
    "    print(f\"Sentiment: {sentiment_window}\\n\")\n",
    "```\n",
    "\n",
    "## 2. Advanced Data Augmentation\n",
    "\n",
    "### 2.1 Synchronized Multi-Transform Pipeline\n",
    "\n",
    "```python\n",
    "class AugmentationPipeline:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, *inputs):\n",
    "        for transform_funcs in zip(*self.transforms):\n",
    "            # Apply corresponding transforms to each input\n",
    "            inputs = tuple(f(x) for f, x in zip(transform_funcs, inputs))\n",
    "        return inputs\n",
    "\n",
    "# Example usage for image and mask augmentation\n",
    "def rotate_image(img): return f\"rotated_{img}\"\n",
    "def rotate_mask(mask): return f\"rotated_{mask}\"\n",
    "def flip_image(img): return f\"flipped_{img}\"\n",
    "def flip_mask(mask): return f\"flipped_{mask}\"\n",
    "\n",
    "pipeline = AugmentationPipeline([\n",
    "    [rotate_image, flip_image],  # transforms for images\n",
    "    [rotate_mask, flip_mask]     # corresponding transforms for masks\n",
    "])\n",
    "\n",
    "image, mask = pipeline(\"image.jpg\", \"mask.png\")\n",
    "```\n",
    "\n",
    "### 2.2 Feature-wise Transformation Pipeline\n",
    "\n",
    "```python\n",
    "class FeatureTransformer:\n",
    "    def __init__(self, feature_names, transformers):\n",
    "        self.feature_names = feature_names\n",
    "        self.transformers = transformers\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # X is a dict of feature arrays\n",
    "        transformed = {}\n",
    "        for name, transformer in zip(self.feature_names, self.transformers):\n",
    "            if transformer is not None:\n",
    "                transformed[name] = transformer(X[name])\n",
    "            else:\n",
    "                transformed[name] = X[name]\n",
    "        return transformed\n",
    "\n",
    "# Usage\n",
    "def normalize(x): return f\"normalized_{x}\"\n",
    "def encode(x): return f\"encoded_{x}\"\n",
    "\n",
    "transformer = FeatureTransformer(\n",
    "    feature_names=['numeric', 'categorical', 'text'],\n",
    "    transformers=[normalize, encode, None]\n",
    ")\n",
    "```\n",
    "\n",
    "## 3. Complex Training Patterns\n",
    "\n",
    "### 3.1 Multi-Task Learning Data Generator\n",
    "\n",
    "```python\n",
    "class MultiTaskBatchGenerator:\n",
    "    def __init__(self, data_sources, task_weights, batch_size=32):\n",
    "        self.data_sources = data_sources\n",
    "        self.task_weights = task_weights\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        iterators = [iter(source) for source in self.data_sources]\n",
    "        task_choices = np.random.choice(\n",
    "            len(self.data_sources),\n",
    "            p=self.task_weights,\n",
    "            size=self.batch_size\n",
    "        )\n",
    "        \n",
    "        while True:\n",
    "            batch = []\n",
    "            for task_idx in task_choices:\n",
    "                try:\n",
    "                    batch.append(next(iterators[task_idx]))\n",
    "                except StopIteration:\n",
    "                    iterators[task_idx] = iter(self.data_sources[task_idx])\n",
    "                    batch.append(next(iterators[task_idx]))\n",
    "            yield batch\n",
    "\n",
    "# Usage\n",
    "task1_data = [(1, 'a'), (2, 'b')]\n",
    "task2_data = [(3, 'c'), (4, 'd')]\n",
    "generator = MultiTaskBatchGenerator(\n",
    "    data_sources=[task1_data, task2_data],\n",
    "    task_weights=[0.7, 0.3]\n",
    ")\n",
    "```\n",
    "\n",
    "### 3.2 Progressive Growing GAN Training\n",
    "\n",
    "```python\n",
    "def progressive_training(generator_stages, discriminator_stages, data_scales):\n",
    "    \"\"\"Training loop for progressive growing GAN.\"\"\"\n",
    "    for g_stage, d_stage, (data, scale) in zip(\n",
    "        generator_stages,\n",
    "        discriminator_stages,\n",
    "        data_scales\n",
    "    ):\n",
    "        g_stage.alpha = scale\n",
    "        d_stage.alpha = scale\n",
    "        \n",
    "        # Training logic here\n",
    "        print(f\"Training at scale {scale}\")\n",
    "        print(f\"Generator stage: {g_stage}\")\n",
    "        print(f\"Discriminator stage: {d_stage}\")\n",
    "        print(f\"Data shape: {data.shape}\\n\")\n",
    "```\n",
    "\n",
    "## 4. Advanced Challenges\n",
    "\n",
    "### Challenge 1: Multi-Modal Data Aligner\n",
    "Create a system that aligns data from multiple sources with different sampling rates:\n",
    "\n",
    "```python\n",
    "def align_multimodal_data(data_streams, target_rate):\n",
    "    \"\"\"\n",
    "    Align multiple data streams with different sampling rates to a target rate.\n",
    "    Each data stream is a tuple of (data, sampling_rate).\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test case\n",
    "video = [(f\"frame_{i}\", 30) for i in range(30)]  # 30 fps\n",
    "audio = [(f\"audio_{i}\", 44100) for i in range(44100)]  # 44.1kHz\n",
    "text = [(f\"text_{i}\", 1) for i in range(1)]  # 1Hz\n",
    "\n",
    "aligned_data = align_multimodal_data(\n",
    "    [video, audio, text],\n",
    "    target_rate=30\n",
    ")\n",
    "```\n",
    "\n",
    "### Challenge 2: Dynamic Feature Pipeline\n",
    "Create a dynamic feature transformation pipeline that can handle different types of features and missing data:\n",
    "\n",
    "```python\n",
    "class DynamicFeaturePipeline:\n",
    "    def __init__(self):\n",
    "        self.transformers = {}\n",
    "        \n",
    "    def add_transformer(self, feature_name, transformer):\n",
    "        # Your code here\n",
    "        pass\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # Your code here\n",
    "        pass\n",
    "        \n",
    "    def fit_transform(self, data):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "# Test case\n",
    "pipeline = DynamicFeaturePipeline()\n",
    "pipeline.add_transformer('numeric', StandardScaler())\n",
    "pipeline.add_transformer('categorical', OneHotEncoder())\n",
    "pipeline.add_transformer('text', TfidfVectorizer())\n",
    "\n",
    "data = {\n",
    "    'numeric': [[1.0], [2.0]],\n",
    "    'categorical': [['A'], ['B']],\n",
    "    'text': ['hello', 'world']\n",
    "}\n",
    "```\n",
    "\n",
    "## 5. Best Practices for ML Pipelines\n",
    "\n",
    "1. **Memory Efficiency:**\n",
    "   ```python\n",
    "   # Bad: Loading all data at once\n",
    "   for x, y in zip(all_features, all_labels):\n",
    "       pass\n",
    "   \n",
    "   # Good: Streaming data\n",
    "   def data_generator(feature_paths, label_paths):\n",
    "       for f_path, l_path in zip(feature_paths, label_paths):\n",
    "           yield load_feature(f_path), load_label(l_path)\n",
    "   ```\n",
    "\n",
    "2. **Error Handling:**\n",
    "   ```python\n",
    "   def robust_zip(*iterables, strict=False):\n",
    "       \"\"\"Zip with error handling for corrupted data.\"\"\"\n",
    "       iterators = [iter(it) for it in iterables]\n",
    "       while True:\n",
    "           try:\n",
    "               yield tuple(map(next, iterators))\n",
    "           except StopIteration:\n",
    "               break\n",
    "           except Exception as e:\n",
    "               if strict:\n",
    "                   raise e\n",
    "               print(f\"Skipping corrupted sample: {e}\")\n",
    "               continue\n",
    "   ```\n",
    "\n",
    "3. **Performance Optimization:**\n",
    "   ```python\n",
    "   from itertools import islice\n",
    "   \n",
    "   def batched_zip(*iterables, batch_size=32):\n",
    "       \"\"\"Memory-efficient batched zip.\"\"\"\n",
    "       iterators = [iter(it) for it in iterables]\n",
    "       while True:\n",
    "           batch = list(islice(zip(*iterators), batch_size))\n",
    "           if not batch:\n",
    "               break\n",
    "           yield zip(*batch)\n",
    "   ```\n",
    "\n",
    "## 6. Real-World ML Pipeline Example\n",
    "\n",
    "Here's a complete example combining many of these patterns:\n",
    "\n",
    "```python\n",
    "class MLPipeline:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_transformers = {}\n",
    "        self.augmenters = {}\n",
    "        \n",
    "    def add_feature_transformer(self, feature_name, transformer):\n",
    "        self.feature_transformers[feature_name] = transformer\n",
    "        \n",
    "    def add_augmenter(self, feature_name, augmenter):\n",
    "        self.augmenters[feature_name] = augmenter\n",
    "        \n",
    "    def process_features(self, features):\n",
    "        transformed = {}\n",
    "        for name, feature in features.items():\n",
    "            # Apply transformation\n",
    "            if name in self.feature_transformers:\n",
    "                feature = self.feature_transformers[name](feature)\n",
    "            # Apply augmentation\n",
    "            if name in self.augmenters:\n",
    "                feature = self.augmenters[name](feature)\n",
    "            transformed[name] = feature\n",
    "        return transformed\n",
    "        \n",
    "    def create_training_batches(self, data_sources):\n",
    "        while True:\n",
    "            batch_features = {name: [] for name in data_sources}\n",
    "            \n",
    "            # Collect batch\n",
    "            for _ in range(self.batch_size):\n",
    "                features = {}\n",
    "                for name, source in data_sources.items():\n",
    "                    try:\n",
    "                        features[name] = next(source)\n",
    "                    except StopIteration:\n",
    "                        data_sources[name] = iter(source.dataset)\n",
    "                        features[name] = next(source)\n",
    "                \n",
    "                # Process features\n",
    "                processed = self.process_features(features)\n",
    "                \n",
    "                # Add to batch\n",
    "                for name, feature in processed.items():\n",
    "                    batch_features[name].append(feature)\n",
    "            \n",
    "            yield batch_features\n",
    "\n",
    "# Usage\n",
    "pipeline = MLPipeline(batch_size=32)\n",
    "pipeline.add_feature_transformer('image', ImageNormalizer())\n",
    "pipeline.add_feature_transformer('text', TextTokenizer())\n",
    "pipeline.add_augmenter('image', ImageAugmenter())\n",
    "\n",
    "data_sources = {\n",
    "    'image': ImageDataset('images/'),\n",
    "    'text': TextDataset('texts/'),\n",
    "    'label': LabelDataset('labels/')\n",
    "}\n",
    "\n",
    "for batch in pipeline.create_training_batches(data_sources):\n",
    "    # Training loop\n",
    "    pass\n",
    "```\n",
    "\n",
    "These patterns become especially useful when:\n",
    "- Handling multiple data modalities\n",
    "- Implementing complex data augmentation\n",
    "- Creating efficient training pipelines\n",
    "- Dealing with streaming data\n",
    "- Managing memory efficiently with large datasets\n",
    "\n",
    "Would you like me to elaborate on any of these patterns or show more examples of a particular use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
